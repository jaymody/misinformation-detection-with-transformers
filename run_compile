#!/bin/bash

################################################################################
################################## Checklist ###################################
################################################################################
# 1. ensure that run/dockerfile/pipeline are appropriately updated
# 2. ensure the current code is in it's on branch named the same as the submission name
# 3. change the submission name in this script (make sure it's unique)
# 4. change the submission description as well
# 5. change google cloud data/model downloads as necessary
# 6. uncomment the vm shutdown at the end if needed



################################################################################
############################## Helper Functions ################################
################################################################################
function print_centered {
     [[ $# == 0 ]] && return 1

     declare -i TERM_COLS=80
     declare -i str_len="${#1}"
     [[ $str_len -ge $TERM_COLS ]] && {
          echo "$1";
          return 0;
     }

     declare -i filler_len="$(( (TERM_COLS - str_len) / 2 ))"
     [[ $# -ge 2 ]] && ch="${2:0:1}" || ch=" "
     filler=""
     for (( i = 0; i < filler_len; i++ )); do
          filler="${filler}${ch}"
     done

     printf "%s%s%s" "$filler" "$1" "$filler"
     [[ $(( (TERM_COLS - str_len) % 2 )) -ne 0 ]] && printf "%s" "${ch}"
     printf "\n"

     return 0
}

function print_title {
    echo ""
    echo ""
    echo ""
    print_centered "-" "-"
    print_centered "$1" "-"
    print_centered "-" "-"
}


################################################################################
#################################### Setup #####################################
################################################################################
# start script timer
script_start_time=`date +%s`

# redirect output to logfile
SCRIPTFILE="${HOME}/run_compile"
LOGFILE="${HOME}/log.txt"
exec > $LOGFILE
exec 2>&1



################################################################################
##################################### Vars #####################################
################################################################################

# edit these for each run
SUBMISSION_NAME="jaymody_phase2_submission_10"
DESCRIPTION="
This submission uses the same pipeline as submission_9 with some minor edits to
the explanation triggers. It also utilizes claimant_model_v3 instead of v2 (v3
has also been trained on phase1 dataset unlike v3).
"
FNC_MODEL_DIR="models/phase2/single-claim-claimant-date/roberta-large-combined-128-2"
RERANK_MODEL_DIR="models/rerank/castroni/monobert-large-msmarco"


# you probably don't need to edit the below params
WORKING_DIR="${HOME}/staging/${SUBMISSION_NAME}"
REPO_URL="git@github.com:jaymody/valerie.git"

DOCKER_IMAGE_NAME="valerie:0"
DOCKER_CONTAINER_NAME="submission_run"

SUBMISSION_TAR_FILE="${SUBMISSION_NAME}.tar"
SUBMISSION_LOG_FILE="${SUBMISSION_NAME}.log"
SUBMISSION_SCORE_FILE="${SUBMISSION_NAME}_score.json"
SUBMISSION_SCRIPT_FILE="${SUBMISSION_NAME}_script.sh"
SUBMISSION_REPORT_FILE="${SUBMISSION_NAME}_report.txt"
SUBMISSION_PREDICTIONS_FILE="${SUBMISSION_NAME}_predictions.json"

GCLOUD_BUCKET="gs://valerie-bucket"
GCLOUD_SUBMISSIONS_DIR="${GCLOUD_BUCKET}/submissions"
GCLOUD_FNC_MODEL_DIR="${GCLOUD_BUCKET}/${FNC_MODEL_DIR}"
GCLOUD_RERANK_MODEL_DIR="${GCLOUD_BUCKET}/${RERANK_MODEL_DIR}"

LOCAL_SUBMISSION_DIR=${SUBMISSION_NAME}



################################################################################
################### Check GCloud Submission Dir Doesn't Exist ##################
################################################################################
gsutil -q stat "${GCLOUD_SUBMISSIONS_DIR}/${LOCAL_SUBMISSION_DIR}/*"
status_value=$?
if [ $status_value == 0 ]; then
    echo "google cloud submissions dir already exists and is not empty, terminating ..."
    exit
fi



################################################################################
################################# Project Dir ##################################
################################################################################
print_title " setting up working dir "
if [ -d "$WORKING_DIR" ]; then
  echo "working directory already exists, terminating ..."
  exit
fi
mkdir -p $WORKING_DIR
cd $WORKING_DIR
git clone -b ${SUBMISSION_NAME} $REPO_URL .
echo ""

mkdir -p models
mkdir -p data/phase2-validation-100
mkdir -p data/phase2-validation-500
mkdir -p logs
mkdir -p ${LOCAL_SUBMISSION_DIR}



################################################################################
################################# Description ##################################
################################################################################
print_title " submission details "
echo "Date: $(date)
Name: ${SUBMISSION_NAME}
Version:

$(git log -1)

Description
-----------
"
echo "$DESCRIPTION"



################################################################################
################################# Init Python ##################################
################################################################################
print_title " init python "
export PATH="${HOME}/.pyenv/bin:$PATH"
eval "$(pyenv init -)"
eval "$(pyenv virtualenv-init -)"
pyenv shell valerie
which python
python --version



################################################################################
############################## Fetch From GCloud ###############################
################################################################################
print_title " downloading gcloud files "

# .envrc should contain: export LEADERS_PRIZE_API_KEY="insert-key-here"
# validation data dir should have metadata.json, with the labels fields removed,
# as well as a metadata-labelled.json with the labels for each claim as a dict
# of key (claim_id) and values (dict of "label" and "related_articles")
gsutil cp "${GCLOUD_BUCKET}/.envrc" .envrc

# tlde set is copied over since we don't have access to internet
# make sure this is the same location specified in .envrc
gsutil cp "${GCLOUD_BUCKET}/models/.tld_set" "models/.tld_set"

# test data
gsutil cp "${GCLOUD_BUCKET}/data/phase2-validation-100/raw/metadata.json" "data/phase2-validation-100/raw/metadata.json"
gsutil cp "${GCLOUD_BUCKET}/data/phase2-validation-100/raw/labels.json" "data/phase2-validation-100/raw/labels.json"

gsutil cp "${GCLOUD_BUCKET}/data/phase2-validation-500/raw/val_metadata_p2.json" "data/phase2-validation-500/raw/metadata.json"
gsutil cp "${GCLOUD_BUCKET}/data/phase2-validation-500/raw/2_labels.json" "data/phase2-validation-500/raw/labels.json"

# copies all files in the model dir (shallow copy, does not follow subdirs)
LOCAL_FNC_DIR="models/fnc"
mkdir -p ${LOCAL_FNC_DIR}
gsutil cp "${GCLOUD_FNC_MODEL_DIR}/*" ${LOCAL_FNC_DIR}

LOCAL_RERANK_DIR="models/rerank"
mkdir -p ${LOCAL_RERANK_DIR}
gsutil cp "${GCLOUD_RERANK_MODEL_DIR}/*" ${LOCAL_RERANK_DIR}

# misc models
gsutil cp "${GCLOUD_BUCKET}/models/source_model.json" models/
gsutil cp "${GCLOUD_BUCKET}/models/claimant_model_v3.json" models/



################################################################################
################## Remove Existing Docker Images/Containers ####################
################################################################################
print_title " remove existing docker image/container "
docker rm ${DOCKER_CONTAINER_NAME}
docker image rm ${DOCKER_IMAGE_NAME}



################################################################################
################################# Build Image ##################################
################################################################################
print_title " docker build "
sudo docker build -t ${DOCKER_IMAGE_NAME} .



################################################################################
################################ Image Summary #################################
################################################################################
print_title " image summary "
docker history -H ${DOCKER_IMAGE_NAME}



################################################################################
######################### Docker Run (500 --net none)  #########################
################################################################################
print_title " docker run (500 --net none) "
docker run \
    --gpus 1 \
    --net none \
    -v ${WORKING_DIR}/data/phase2-validation-500/raw:/usr/local/dataset/:ro \
    --name ${DOCKER_CONTAINER_NAME} \
    -e LANG=C.UTF-8 \
    ${DOCKER_IMAGE_NAME}

echo "copying predictions json from container"
docker cp ${DOCKER_CONTAINER_NAME}:/usr/local/predictions.json "${LOCAL_SUBMISSION_DIR}/${SUBMISSION_PREDICTIONS_FILE}"

echo "computing submission score/report"
echo ""
python ${WORKING_DIR}/scripts/score_predictions_file.py \
    --metadata_labelled_file "data/phase2-validation-500/raw/labels.json" \
    --predictions_file "${LOCAL_SUBMISSION_DIR}/${SUBMISSION_PREDICTIONS_FILE}" \
    --print true



################################################################################
############################### Docker Run (100) ###############################
################################################################################
print_title " docker run (100) "
docker rm ${DOCKER_CONTAINER_NAME}

# for the actual submission, the --net=none option would also be set
# for cpu use docker, for gpus use nvidia-docker --gpus 1
run_start_time=`date +%s`
docker run \
    --gpus 1 \
    -v ${WORKING_DIR}/data/phase2-validation-100/raw:/usr/local/dataset/:ro \
    --name ${DOCKER_CONTAINER_NAME} \
    -e LANG=C.UTF-8 \
    ${DOCKER_IMAGE_NAME}
run_end_time=`date +%s`
DOCKER_RUNTIME_100=$((run_end_time-run_start_time))

echo "copying predictions json from container"
docker cp ${DOCKER_CONTAINER_NAME}:/usr/local/predictions.json "${LOCAL_SUBMISSION_DIR}/${SUBMISSION_PREDICTIONS_FILE}"

echo "computing submission score/report"
echo ""
python ${WORKING_DIR}/scripts/score_predictions_file.py \
    --metadata_labelled_file "data/phase2-validation-100/raw/labels.json" \
    --predictions_file "${LOCAL_SUBMISSION_DIR}/${SUBMISSION_PREDICTIONS_FILE}" \
    --score_file "${LOCAL_SUBMISSION_DIR}/${SUBMISSION_SCORE_FILE}" \
    --report_file "${LOCAL_SUBMISSION_DIR}/${SUBMISSION_REPORT_FILE}" \
    --print true



################################################################################
################################# Docker Save ##################################
################################################################################
print_title " saving docker image to tar "
docker save ${DOCKER_IMAGE_NAME} | tqdm --bytes --total $(docker image inspect ${DOCKER_IMAGE_NAME} --format='{{.Size}}') > "${LOCAL_SUBMISSION_DIR}/${SUBMISSION_TAR_FILE}"
du -h ${LOCAL_SUBMISSION_DIR}/*.tar



################################################################################
########################### Upload Files to GCloud #############################
################################################################################
print_title " uploading submission "
cp ${SCRIPTFILE} "${LOCAL_SUBMISSION_DIR}/${SUBMISSION_SCRIPT_FILE}"
gsutil -m cp -r "${LOCAL_SUBMISSION_DIR}" ${GCLOUD_SUBMISSIONS_DIR}



################################################################################
################################### Cleanup ####################################
################################################################################
print_title " cleanup "
cd ${HOME}
docker rm ${DOCKER_CONTAINER_NAME}
docker image rm ${DOCKER_IMAGE_NAME}
rm -rf ${WORKING_DIR}
df -h



################################################################################
#################################### Times #####################################
################################################################################
script_end_time=`date +%s`
SCRIPT_RUNTIME=$((script_end_time-script_start_time))
print_title " times
Total:          $(printf '%02dh:%02dm:%02ds\n' $((${SCRIPT_RUNTIME}/3600)) $((${SCRIPT_RUNTIME}%3600/60)) $((${SCRIPT_RUNTIME}%60)))
Container 100:  $(printf '%02dh:%02dm:%02ds\n' $((${DOCKER_RUNTIME_100}/3600)) $((${DOCKER_RUNTIME_100}%3600/60)) $((${DOCKER_RUNTIME_100}%60)))
"



################################################################################
##################################### Done #####################################
################################################################################
print_title " done "
gsutil cp ${LOGFILE} "${GCLOUD_SUBMISSIONS_DIR}/${LOCAL_SUBMISSION_DIR}/${SUBMISSION_LOG_FILE}"



################################################################################
################################ Stop Instance #################################
################################################################################
# print_title " stopping instance "
# gcloud compute instances stop --zone "us-central1-a" valerie-gpu

print_title " done done "
