{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aFcE0lSqYag4"
   },
   "source": [
    "# Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ruKsHPGPblRV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import heapq\n",
    "import pickle\n",
    "import random\n",
    "import multiprocessing\n",
    "\n",
    "import spacy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from valerie.utils import get_logger\n",
    "from valerie.preprocessing import extract_words_from_url, clean_text\n",
    "from valerie.scoring import validate_predictions_phase2, compute_score_phase2\n",
    "from valerie.modeling import SequenceClassificationModel, SequenceClassificationDataset, SequenceClassificationExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sT0p85DUbe5L"
   },
   "outputs": [],
   "source": [
    "_logger = get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTPKlXP4dElX"
   },
   "outputs": [],
   "source": [
    "with open(\"data/phase2-validation-100/processed/responses.pkl\", \"rb\") as fi:\n",
    "    responses = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y1E-o-DMbBsR"
   },
   "outputs": [],
   "source": [
    "def compute_responses_score(results, claims_dict):\n",
    "    predictions = {}\n",
    "    perfect_predictions = {}\n",
    "    labels = {}\n",
    "\n",
    "    for k, hits in results.items():\n",
    "        claim = claims_dict[k]\n",
    "        labels[claim.id] = claim.to_dict()\n",
    "        \n",
    "        hits = sorted(hits, key=lambda x: x[1], reverse=True) # sort by score\n",
    "        predictions[claim.id] = {\n",
    "            \"label\": claim.label,\n",
    "            \"explanation\": \"\",\n",
    "            \"related_articles\": {\n",
    "                i + 1: x\n",
    "                for i, x in enumerate([v[0] for v in hits[:2]])\n",
    "            }\n",
    "        }\n",
    "        perfect_predictions[claim.id] = {\n",
    "            \"label\": claim.label,\n",
    "            \"explanation\": \"\",\n",
    "            \"related_articles\": {\n",
    "                i + 1: x\n",
    "                for i, x in enumerate([v[0] for v in hits if v[0] in claim.related_articles.values()][:2])\n",
    "            }\n",
    "        }\n",
    "\n",
    "    validate_predictions_phase2(predictions)\n",
    "    score = compute_score_phase2(labels, predictions)\n",
    "    validate_predictions_phase2(perfect_predictions)\n",
    "    perfect_score = compute_score_phase2(labels, perfect_predictions)\n",
    "    return {\n",
    "        \"perfect_rerank_score\": perfect_score[\"score\"],\n",
    "        \"perfect_rerank_error\": perfect_score[\"error\"],\n",
    "        \"api_score\": score[\"score\"],\n",
    "        \"api_error\": score[\"error\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_a(claim):\n",
    "    text_a = claim.claim\n",
    "    text_a += \" \"\n",
    "    text_a += claim.claimant if claim.claimant else \"no claimant\"\n",
    "    text_a += \" \"\n",
    "    text_a += claim.date.split()[0].split(\"T\")[0] if claim.date else \"no date\"\n",
    "    return clean_text(text_a)\n",
    "\n",
    "def create_text_b_content(article):\n",
    "    text_b = \"\"\n",
    "    if article.source:\n",
    "        text_b += article.source + \". \"\n",
    "    if article.title:\n",
    "        text_b += article.title + \". \"\n",
    "    if article.url:\n",
    "        url_words = extract_words_from_url(article.url)\n",
    "        if url_words:\n",
    "            text_b += \" \".join(url_words) + \". \"\n",
    "    if article.content:\n",
    "        text_b += article.content\n",
    "    return clean_text(text_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Spacy on Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misses = 0\n",
    "claims_list = []\n",
    "for res in tqdm(responses):\n",
    "    if not res[\"res\"]:\n",
    "        misses += 1\n",
    "        continue\n",
    "    claim = res[\"claim\"]\n",
    "    claim.text_a = create_text_a(claim)\n",
    "    claim.res = res\n",
    "    claim.support = {}\n",
    "    claims_list.append(claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_texts = [claim.text_a for claim in claims_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_docs = [doc for doc in tqdm(nlp.pipe(claims_texts, n_process=16, disable=[\"textcat\", \"tagger\", \"parser\", \"ner\"]), total=len(claims_texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_dict = {}\n",
    "for claim, doc in tqdm(zip(claims_list, claims_docs)):\n",
    "    claim.doc = doc\n",
    "    claims_dict[claim.index] = claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(claims_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(claims_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3e771ad73243a9bdad67b6c152fa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "misses = 0\n",
    "articles_list = []\n",
    "for res in tqdm(responses):\n",
    "    if not res[\"res\"]:\n",
    "        misses += 1\n",
    "        continue\n",
    "    for hit in res[\"res\"][\"hits\"][\"hits\"]:\n",
    "        article = hit[\"article\"]\n",
    "#         article.text_b = create_text_b_content(article)\n",
    "        articles_list.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2822"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1973"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(articles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_list = list(set(articles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9f441b96a4448a913e837665f671bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1973.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def _text_b_text(article):\n",
    "    return article, create_text_b_content(article)\n",
    "\n",
    "articles_texts = {}\n",
    "pool = multiprocessing.Pool(16)\n",
    "for article, text_b in tqdm(pool.imap_unordered(_text_b_text, articles_list), total=len(articles_list)):\n",
    "    articles_texts[article.index] = text_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in articles_list:\n",
    "    article.text_b = articles_texts[article.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5ab3d118a043a0a0332c7ba5624f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1973.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "articles_texts = [article.text_b for article in tqdm(articles_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3698d0c56b6416b95722fd68940ae0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1973.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "articles_docs = [doc for doc in tqdm(nlp.pipe(articles_texts, n_process=16, disable=[\"textcat\", \"tagger\", \"ner\"]), total=len(articles_texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6744d094b9f84c2eb113a7af4466439d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "articles_dict = {}\n",
    "for article, doc in tqdm(zip(articles_list, articles_docs)):\n",
    "    article.doc = doc\n",
    "    articles_dict[article.index] = article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYiga7bObTzu"
   },
   "source": [
    "# Examples\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_b_curated(article, claim):\n",
    "    support = []\n",
    "    for sent in article.doc.sents:\n",
    "        support.append({\n",
    "            \"text\": sent.text,\n",
    "            \"score\": claim.doc.similarity(sent)\n",
    "        })\n",
    "    support = heapq.nlargest(32, support, key=lambda x: x[\"score\"])\n",
    "    claim.support[article.index] = support\n",
    "    text_b = clean_text(\" \".join([s[\"text\"] for s in support]))\n",
    "    return text_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e00a5ba1434f608c5412619625ded9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "examples = []\n",
    "for claim in tqdm(claims_dict.values()):\n",
    "    hits_indices = [hit[\"url\"] for hit in claim.res[\"res\"][\"hits\"][\"hits\"]]\n",
    "    hits = [articles_dict[idx] for idx in hits_indices]\n",
    "    \n",
    "    related_articles_url_set = set(claim.related_articles.values())\n",
    "\n",
    "    for article in hits:\n",
    "        article.text_b = create_text_b_curated(article, claim)\n",
    "\n",
    "        examples.append(SequenceClassificationExample(\n",
    "            guid=claim.index,\n",
    "            text_a=claim.text_a,\n",
    "            text_b=article.text_b,\n",
    "            label=1 if article.url in related_articles_url_set else 0,\n",
    "            art_id=article.index\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "1973\n",
      "\n",
      "3000\n",
      "2822\n"
     ]
    }
   ],
   "source": [
    "print(len(claims_dict))\n",
    "print(len(articles_dict))\n",
    "print()\n",
    "print(len(claims_dict)*30)\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DamT2JLogphk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"guid\": \"Phase2Validation100Dataset/52\",\n",
       "  \"text_a\": \"U.S. President Donald Trump has voted via mailed absentee ballot in United States elections. no claimant 2020-05-21\",\n",
       "  \"text_b\": \"the state authorized no-reason absentee voting in a referendum in 2018. trump threatens to stop funding for michigan if absentee ballot forms sent to voters secretary of state jocelyn benson speaks outside absentee ballot counting on march, 10, 2020, at the tcf center in detroit. washington \\u2013 president donald trump on wednesday threatened funding for michigan amid a global health pandemic if state officials move ahead with plans to send absentee ballot applications to every state voter. the president said if secretary of state jocelyn benson sends out absentee ballot applications to voters he will withhold funding, suggesting its illegal. free story news politics elections donald trump michigan absentee ballot applications. \\\" breaking: michigan sends absentee ballots to 7.7 million people ahead of primaries and the general election. michigan holds primaries for offices other than president in august and the national general election is on the first tuesday of november. trump made a similar threat on twitter on wednesday morning about efforts in nevada to ensure voters get absentee ballots. mcenany also quoted criticism of widespread absentee voting , led by former president jimmy carter, a democrat, and former u.s. secretary of state james baker, a republican. democrats say generally that republican opposition to voting by mail is intended to hold down turnout, especially among supporters of democratic candidates. while it is illegal in michigan to send absentee ballots to voters who do not formally request them, it is far from clear that there are the same legal hurdles to sending applications for the absentee ballots to registered voters, though it could be challenged in court. trump threatens to withhold michigan funding over absentee ballot apps. that report, in one section, said absentee ballots \\\"remain the largest source of potential voter fraud.\\\" as to why he hasn't criticized some other states \\u2014 including those led by republican governors \\u2014 for encouraging more absentee voting, she referred the question to the trump campaign. in his first post, it was unclear the president understood what he was talking about, as he suggested michigan was in the process of sending absentee ballots themselves \\u2014 not the applications for people to ask for absentee ballots if they wish \\u2014 to voters. last week, the state benson's office has said it will cost about $4.5 million to send out absentee ballot applications to every voter, with some funding expected to come from that \\u2014 michigan secretary of state jocelyn benson on tuesday morning said, so they can, if they choose to do so, take part in the aug. 4 and nov. 3 elections without going to polling places. on wednesday, mcenany said there is \\\"a lot of fraud potentially at play when you have mass absentee balloting\\\" and that the president only supports absentee balloting for a reason. benson and some local clerks sent out applications to voters before the may 5 local elections in response to the pandemic. he wrote it's illegal for anyone to send unsolicited absentee ballots to voters and said if it occurs, he will \\\"ask to hold up funding to michigan if they want to go down this voter fraud path! let friends in your social network know what you are reading about trump threatens to stop funding for michigan if absentee ballot forms sent to voters but trump, who has railed against widespread voting by mail, posted on twitter about 7:50 a.m. a suggestion that if she did so, he would move to block funding for michigan. asked specifically what laws trump believed benson was violating, mcenany refused to answer saying it was a campaign matter, though trump's threat was clearly made as president \\u2014 not as a candidate. there has trump has complained of corruption, but he has voted by mail himself in new york when he lived there and, this year, in florida, which he has officially made his state of residence. speaking to reporters at the white house, trump press secretary kayleigh mcenany said wednesday afternoon the president's tweets were \\\"meant to alert (treasury secretary steve mnuchin and acting office of management and budget director russell vought) about his concerns\\\" with trillions in funding headed out to the states. trump unclear what funding he's talking about trump wasn't clear about what funding he was referring to, but michigan is expected to receive billions in coronavirus aid from the federal government , including a portion of $400 million set aside to the states to prepare for this year's elections under the threat of the pandemic. but the report also made clear that admonition was about ballots \\u2014 not applications \\u2014 and that states could overcome those criticisms by passing restrictions on who has access to ballots and taking campaign workers out of the process. little evidence of rampant corruption in absentee voting while there have been concerns raised nationally, especially among republicans, about the potential for corruption and missing ballots, this was done illegally and without authorization by a rogue secretary of state. trump won michigan by less than two-tenths of 1% of the vote in michigan four years ago. by receiving absentee ballot applications at home, as proposed by benson, voters could fill them out and mail or drop them off at local clerks' offices or take a photo of them and email them to clerks, saving them an in-person visit. \\\" calling that illegal, however, is on far shakier ground than sending out absentee ballots themselves.\",\n",
       "  \"label\": 0,\n",
       "  \"art_id\": \"https://www.freep.com/story/news/politics/elections/2020/05/20/donald-trump-michigan-absentee-ballot-applications/5227024002/\"\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S. President Donald Trump has voted via mailed absentee ballot in United States elections.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(claims_dict.values())[0].claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(list(claims_dict.values())[0].support, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCteL6dXbX53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "2822\n"
     ]
    }
   ],
   "source": [
    "print(len(responses)*16)\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Ocq58LFblA_"
   },
   "source": [
    "# Predict\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNS6evMZbpsU"
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
    "os.environ[\"WANDB_WATCH\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"castorini/monot5-base-msmarco\"\n",
    "# \"castorini/monobert-large-msmarco\"\n",
    "# \"nboost/pt-bert-large-msmarco\"]:\n",
    "pretrained_model_name_or_path = \"castorini/monobert-large-msmarco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-14 01:03:34,870] INFO:transformers.configuration_utils: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/castorini/monobert-large-msmarco/config.json from cache at /home/jay/.cache/torch/transformers/643500d870067d59f219f7b5652919267c01bfa98024e2e74f53b28c1b6aff2b.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38\n",
      "[2020-07-14 01:03:34,872] INFO:transformers.configuration_utils: Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-07-14 01:03:34,872] INFO:transformers.tokenization_utils_base: Model name 'castorini/monobert-large-msmarco' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'castorini/monobert-large-msmarco' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "[2020-07-14 01:03:35,602] INFO:transformers.tokenization_utils_base: loading file https://s3.amazonaws.com/models.huggingface.co/bert/castorini/monobert-large-msmarco/vocab.txt from cache at /home/jay/.cache/torch/transformers/7e579d33b9ca381ae377521c4918fb66ee50a10d0fa955173dc5ad550a05b40c.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2020-07-14 01:03:35,602] INFO:transformers.tokenization_utils_base: loading file https://s3.amazonaws.com/models.huggingface.co/bert/castorini/monobert-large-msmarco/added_tokens.json from cache at /home/jay/.cache/torch/transformers/cba5f19d6689880029e5bccfd5e3c905f2067168a27322e8c7a4bf55b5a9a0ad.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "[2020-07-14 01:03:35,603] INFO:transformers.tokenization_utils_base: loading file https://s3.amazonaws.com/models.huggingface.co/bert/castorini/monobert-large-msmarco/special_tokens_map.json from cache at /home/jay/.cache/torch/transformers/01358c6ecc96532f113f6b9633dcef2fbe2e8142997f6b296df5a9ffb4ae19ab.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "[2020-07-14 01:03:35,603] INFO:transformers.tokenization_utils_base: loading file https://s3.amazonaws.com/models.huggingface.co/bert/castorini/monobert-large-msmarco/tokenizer_config.json from cache at /home/jay/.cache/torch/transformers/1ed92dc6896c1ff8e5e65d28cb4bebc094ac70f3c961fabb25e0e1e4729b919c.3fc3a7b9028b25d25e6393f1d27ed643eb6ba9ce4113c05aa13277951cff117c\n",
      "[2020-07-14 01:03:35,603] INFO:transformers.tokenization_utils_base: loading file https://s3.amazonaws.com/models.huggingface.co/bert/castorini/monobert-large-msmarco/tokenizer.json from cache at None\n",
      "[2020-07-14 01:03:35,787] INFO:transformers.configuration_utils: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/castorini/monobert-large-msmarco/config.json from cache at /home/jay/.cache/torch/transformers/643500d870067d59f219f7b5652919267c01bfa98024e2e74f53b28c1b6aff2b.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38\n",
      "[2020-07-14 01:03:35,788] INFO:transformers.configuration_utils: Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-07-14 01:03:35,839] INFO:transformers.modeling_utils: loading weights file https://cdn.huggingface.co/castorini/monobert-large-msmarco/pytorch_model.bin from cache at /home/jay/.cache/torch/transformers/c48fb89cc59db72299f77c13a9f914ae2dd73cae21dcdcef4281c0308e2f4075.454581226736f9af4828c8d3a034ecd8c0c174c620fcb9356260b0342591de76\n",
      "[2020-07-14 01:03:44,726] INFO:transformers.modeling_utils: All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "[2020-07-14 01:03:44,727] INFO:transformers.modeling_utils: All the weights of BertForSequenceClassification were initialized from the model checkpoint at castorini/monobert-large-msmarco.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = SequenceClassificationModel.from_pretrained(pretrained_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-14 01:03:44,735] INFO:valerie.modeling: ... converting examples to features ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38eb330be520463187013abf84a81531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='converting examples to features', max=2822.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "examples_dataset = model.create_dataset(examples, nproc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,3,4,5,6,7\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-14 01:04:45,529] INFO:transformers.training_args: PyTorch: setting up devices\n",
      "[2020-07-14 01:04:49,207] INFO:transformers.trainer: Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "[2020-07-14 01:04:49,210] INFO:transformers.trainer: ***** Running Prediction *****\n",
      "[2020-07-14 01:04:49,210] INFO:transformers.trainer:   Num examples = 2822\n",
      "[2020-07-14 01:04:49,210] INFO:transformers.trainer:   Batch size = 2048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0801ed51c44440ea9abaf9568efb7bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction', max=2.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay/miniconda3/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_output = model.predict(examples_dataset, predict_batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2YvlHrobmdq"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1d54a3cd4f40788c558054063785cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "api\n",
      "{\n",
      "  \"perfect_rerank_score\": 0.9617898441427853,\n",
      "  \"perfect_rerank_error\": \"'None'\",\n",
      "  \"api_score\": 0.5780794369029664,\n",
      "  \"api_error\": \"'None'\"\n",
      "}\n",
      "\n",
      "trans\n",
      "{\n",
      "  \"perfect_rerank_score\": 0.9617898441427853,\n",
      "  \"perfect_rerank_error\": \"'None'\",\n",
      "  \"api_score\": 0.5558069381598794,\n",
      "  \"api_error\": \"'None'\"\n",
      "}\n",
      "\n",
      "both\n",
      "{\n",
      "  \"perfect_rerank_score\": 0.9617898441427853,\n",
      "  \"perfect_rerank_error\": \"'None'\",\n",
      "  \"api_score\": 0.6082453494218201,\n",
      "  \"api_error\": \"'None'\"\n",
      "}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "claims_dict = {res[\"claim\"].index: res[\"claim\"] for res in responses if res[\"res\"]}\n",
    "api_scores_dict = {\n",
    "    res[\"claim\"].index: {\n",
    "        hit[\"article\"].index: hit[\"score\"] for hit in res[\"res\"][\"hits\"][\"hits\"]\n",
    "    }\n",
    "    for res in responses\n",
    "    if res[\"res\"]\n",
    "}\n",
    "\n",
    "\n",
    "rerank_just_api_responses = {\n",
    "    res[\"claim\"].index: [\n",
    "        (hit[\"article\"].index, hit[\"score\"]) for hit in res[\"res\"][\"hits\"][\"hits\"]\n",
    "    ]\n",
    "    for res in responses\n",
    "    if res[\"res\"]\n",
    "}\n",
    "\n",
    "rerank_just_trans_responses = {res[\"claim\"].index: [] for res in responses if res[\"res\"]}\n",
    "\n",
    "rerank_both_responses = {\n",
    "    res[\"claim\"].index: []\n",
    "    for res in responses\n",
    "    if res[\"res\"]\n",
    "}\n",
    "\n",
    "for example, proba in tqdm(zip(examples, predict_output.predictions)):\n",
    "    proba = float(proba[1]) # get probability that the article is related\n",
    "\n",
    "    rerank_just_trans_responses[example.guid].append((example.art_id, proba))\n",
    "    rerank_both_responses[example.guid].append((example.art_id, proba + api_scores_dict[example.guid][example.art_id]))\n",
    "    \n",
    "print('api')\n",
    "print(json.dumps(compute_responses_score(rerank_just_api_responses, claims_dict), indent=2))\n",
    "print()\n",
    "print('trans')\n",
    "print(json.dumps(compute_responses_score(rerank_just_trans_responses, claims_dict), indent=2))\n",
    "print()\n",
    "print('both')\n",
    "print(json.dumps(compute_responses_score(rerank_both_responses, claims_dict), indent=2))\n",
    "print()\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, hits in rerank_just_api_responses.items():\n",
    "     rerank_just_api_responses[k] = sorted(hits, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "for k, hits in rerank_just_trans_responses.items():\n",
    "     rerank_just_trans_responses[k] = sorted(hits, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for k, hits in rerank_both_responses.items():\n",
    "     rerank_both_responses[k] = sorted(hits, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idx = list(rerank_just_api_responses.keys())[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": 59,\n",
      "  \"claim\": \"Racial comparisons on coronavirus statistics in Monroe County, N.Y., show that the impact on minorities is \\u201cbasically on par, a little bit up, from the population numbers,\\u201d meaning that \\u201cwe don\\u2019t see that disparity as much here.\\u201d\",\n",
      "  \"claimant\": \"Lovely Warren\",\n",
      "  \"date\": \"2020-04-08 00:00:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(claims_dict[example_idx].logstr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(claims_dict[example_idx].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Phase2Validation100Dataset/2479.html\": \"https://www.cdc.gov/nchs/nvss/vsrr/covid_weekly/\",\n",
      "  \"Phase2Validation100Dataset/2482.html\": \"https://www.census.gov/quickfacts/monroecountynewyork\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(claims_dict[example_idx].related_articles, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http://www.sentencingproject.org/publications/color-of-justice-racial-and-ethnic-disparity-in-state-prisons/',\n",
       "  72.98848),\n",
       " ('https://www.sentencingproject.org/publications/color-of-justice-racial-and-ethnic-disparity-in-state-prisons/',\n",
       "  72.964645),\n",
       " ('https://www.cbc.ca/news/world/covid-19-us-canada-death-rates-1.5553168?fbclid=iwar1jx3u-vaussuwhpci4s0phagtxukcnzyytfbmt6g54ubm4jck6qqrjqts',\n",
       "  70.62437),\n",
       " ('https://www.sentencingproject.org/publications/un-report-on-racial-disparities/',\n",
       "  64.58491),\n",
       " ('https://www.hrw.org/news/2009/06/19/race-drugs-and-law-enforcement-united-states#_ftn17',\n",
       "  63.59014)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_just_api_responses[example_idx][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.cbc.ca/news/world/covid-19-us-canada-death-rates-1.5553168?fbclid=iwar1jx3u-vaussuwhpci4s0phagtxukcnzyytfbmt6g54ubm4jck6qqrjqts',\n",
       "  2.959611415863037),\n",
       " ('https://www.vox.com/2020/5/4/21242750/coronavirus-covid-19-united-states-canada-trump-trudeau',\n",
       "  1.7351104021072388),\n",
       " ('https://www.nytimes.com/2020/05/01/world/canada/america-canada-coronavirus-comparison.html',\n",
       "  -1.714412808418274),\n",
       " ('https://www.statnews.com/2020/04/17/influential-covid-19-model-uses-flawed-methods-shouldnt-guide-policies-critics-say/',\n",
       "  -1.978223443031311),\n",
       " ('https://www.npr.org/sections/goatsandsoda/2020/03/20/815408287/how-the-novel-coronavirus-and-the-flu-are-alike-and-different',\n",
       "  -2.0584213733673096)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_just_trans_responses[example_idx][:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.cbc.ca/news/world/covid-19-us-canada-death-rates-1.5553168?fbclid=iwar1jx3u-vaussuwhpci4s0phagtxukcnzyytfbmt6g54ubm4jck6qqrjqts',\n",
       "  73.58398141586304),\n",
       " ('http://www.sentencingproject.org/publications/color-of-justice-racial-and-ethnic-disparity-in-state-prisons/',\n",
       "  69.76469507644653),\n",
       " ('https://www.sentencingproject.org/publications/color-of-justice-racial-and-ethnic-disparity-in-state-prisons/',\n",
       "  69.74086007644654),\n",
       " ('https://www.sentencingproject.org/publications/un-report-on-racial-disparities/',\n",
       "  60.10208233657836),\n",
       " ('https://www.hrw.org/news/2009/06/19/race-drugs-and-law-enforcement-united-states#_ftn17',\n",
       "  58.874018326416014)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_both_responses[example_idx][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results restricted 16 and 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results when restring text_b to first 16 most relevant sentences and resulting the hits to the first 16 retrieved articles\n",
    "\n",
    "# api\n",
    "# {\n",
    "#   \"perfect_rerank_score\": 0.9617898441427853,\n",
    "#   \"perfect_rerank_error\": \"'None'\",\n",
    "#   \"api_score\": 0.5780794369029664,\n",
    "#   \"api_error\": \"'None'\"\n",
    "# }\n",
    "\n",
    "# trans\n",
    "# {\n",
    "#   \"perfect_rerank_score\": 0.8001005530417297,\n",
    "#   \"perfect_rerank_error\": \"'None'\",\n",
    "#   \"api_score\": 0.5578179989944696,\n",
    "#   \"api_error\": \"'None'\"\n",
    "# }\n",
    "\n",
    "# both\n",
    "# {\n",
    "#   \"perfect_rerank_score\": 0.8001005530417297,\n",
    "#   \"perfect_rerank_error\": \"'None'\",\n",
    "#   \"api_score\": 0.6082453494218201,\n",
    "#   \"api_error\": \"'None'\"\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "__experiment.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
