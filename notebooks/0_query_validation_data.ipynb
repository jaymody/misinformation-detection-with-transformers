{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copied From Query.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import argparse\n",
    "import multiprocessing\n",
    "\n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from valerie import search\n",
    "from valerie.data import Article\n",
    "from valerie.datasets import name_to_dataset\n",
    "from valerie.utils import get_logger\n",
    "from valerie.scoring import validate_predictions_phase2, compute_score_phase2\n",
    "from valerie.preprocessing import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logger = get_logger()\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_responses_score(responses):\n",
    "    predictions = {}\n",
    "    perfect_predictions = {}\n",
    "    labels = {}\n",
    "\n",
    "    for v in responses:\n",
    "        claim = v[\"claim\"]\n",
    "        labels[claim.id] = claim.to_dict()\n",
    "        predictions[claim.id] = {\n",
    "            \"label\": claim.label,\n",
    "            \"related_articles\": {\n",
    "                i + 1: x\n",
    "                for i, x in enumerate(\n",
    "                    [hit[\"url\"] for hit in v[\"res\"][\"hits\"][\"hits\"][:2]]\n",
    "                )\n",
    "            }\n",
    "            if v[\"res\"]\n",
    "            else {},\n",
    "            \"explanation\": \"\",\n",
    "        }\n",
    "        perfect_predictions[claim.id] = {\n",
    "            \"label\": claim.label,\n",
    "            \"related_articles\": {\n",
    "                i + 1: x\n",
    "                for i, x in enumerate(\n",
    "                    [\n",
    "                        hit[\"url\"]\n",
    "                        for hit in v[\"res\"][\"hits\"][\"hits\"]\n",
    "                        if hit[\"url\"] in claim.related_articles.values()\n",
    "                    ][:2]\n",
    "                )\n",
    "            }\n",
    "            if v[\"res\"]\n",
    "            else {},\n",
    "            \"explanation\": \"\",\n",
    "        }\n",
    "\n",
    "    validate_predictions_phase2(predictions)\n",
    "    score = compute_score_phase2(labels, predictions)\n",
    "    validate_predictions_phase2(perfect_predictions)\n",
    "    perfect_score = compute_score_phase2(labels, perfect_predictions)\n",
    "    return {\n",
    "        \"perfect_rerank_score\": perfect_score[\"score\"],\n",
    "        \"perfect_rerank_error\": perfect_score[\"error\"],\n",
    "        \"api_score\": score[\"score\"],\n",
    "        \"api_error\": score[\"error\"],\n",
    "    }\n",
    "\n",
    "def convert_html_hits_to_article(res):\n",
    "    visited = set()\n",
    "    output = []\n",
    "\n",
    "    for hit in res[\"hits\"][\"hits\"]:\n",
    "        if hit[\"url\"] in visited:\n",
    "            continue\n",
    "\n",
    "        article = Article.from_html(hit[\"url\"], hit[\"content\"], url=hit[\"url\"])\n",
    "        if not article.content or len(article.content) < 32:\n",
    "            continue\n",
    "\n",
    "        output.append({\"score\": hit[\"score\"], \"article\": article, \"url\": hit[\"url\"]})\n",
    "        visited.add(hit[\"url\"])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def pipeline(claim):\n",
    "    query = query_expansion(claim)\n",
    "    res = search.query(query)\n",
    "    if res:\n",
    "        res[\"hits\"][\"hits\"] = convert_html_hits_to_article(res)\n",
    "    return claim, query, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset_name=\"Phase2ValidationDataset\", truncate=None, nproc=8):\n",
    "    dataset_class = name_to_dataset[dataset_name]\n",
    "    claims = dataset_class.from_raw().claims\n",
    "    if truncate:\n",
    "        claims = random.sample(claims, k=truncate)\n",
    "\n",
    "    pool = multiprocessing.Pool(nproc)\n",
    "    responses = []\n",
    "    for claim, query, res in tqdm(\n",
    "        pool.imap_unordered(pipeline, claims),\n",
    "        total=len(claims),\n",
    "        desc=\"fetching responses\",\n",
    "    ):\n",
    "        responses.append({\"claim\": claim, \"res\": res, \"query\": query})\n",
    "\n",
    "#     with open(args.output_file, \"wb\") as fo:\n",
    "#         pickle.dump(responses, fo)\n",
    "\n",
    "    _logger.warning(\"Missed Queries: %d\", sum(1 for v in responses if v[\"res\"] is None))\n",
    "    _logger.info(\"Scores: %s\", json.dumps(compute_responses_score(responses), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No QE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expansion(claim):\n",
    "    return claim.claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a00a217d8243dcaff8aa156d6afea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Phase2ValidationDataset to claims', max=500.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:19:04,859] INFO:valerie.datasets: missed row to claim conversions: 0\n",
      "[2020-07-11 19:19:04,859] INFO:valerie.datasets: Phase2ValidationDataset claims set change 500 --> 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15a10d0f8f34924979f9eb124ec08aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='fetching responses', max=500.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:21:07,341] WARNING:root: Missed Queries: 0\n",
      "[2020-07-11 19:21:07,370] INFO:root: Scores: {\n",
      "  \"perfect_rerank_score\": 1.0441553640250065,\n",
      "  \"perfect_rerank_error\": \"'None'\",\n",
      "  \"api_score\": 0.5477855697093302,\n",
      "  \"api_error\": \"'None'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expansion(claim):\n",
    "    claim_doc = nlp(claim.claim, disable=[\"textcat\", \"tagger\", \"parser\", \"ner\"])\n",
    "\n",
    "    # stopword removal\n",
    "    query_words = [token.text for token in claim_doc if not token.is_stop]\n",
    "    query = \" \".join([t for t in query_words if t])\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35840491dea4b7686491390abc6bffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Phase2ValidationDataset to claims', max=500.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:22:50,656] INFO:valerie.datasets: missed row to claim conversions: 0\n",
      "[2020-07-11 19:22:50,657] INFO:valerie.datasets: Phase2ValidationDataset claims set change 500 --> 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad8501dd4fc4c78b9f849a07871d3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='fetching responses', max=500.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:24:43,148] WARNING:root: Missed Queries: 0\n",
      "[2020-07-11 19:24:43,175] INFO:root: Scores: {\n",
      "  \"perfect_rerank_score\": 1.0108953197043262,\n",
      "  \"perfect_rerank_error\": \"'None'\",\n",
      "  \"api_score\": 0.5283960558501345,\n",
      "  \"api_error\": \"'None'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopword Removal + Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expansion(claim):\n",
    "    claim_doc = nlp(claim.claim, disable=[\"textcat\", \"tagger\", \"parser\", \"ner\"])\n",
    "\n",
    "    # stopword removal\n",
    "    query_words = [token.text for token in claim_doc if not token.is_stop]\n",
    "    query = clean_text(\n",
    "        \" \".join(\n",
    "            [\n",
    "                t\n",
    "                for t in query_words\n",
    "                if t and not len(clean_text(t, remove_punctuation=True)) == 0\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8742302be50c4ae5a5877e674967c5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Phase2ValidationDataset to claims', max=500.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:24:43,485] INFO:valerie.datasets: missed row to claim conversions: 0\n",
      "[2020-07-11 19:24:43,486] INFO:valerie.datasets: Phase2ValidationDataset claims set change 500 --> 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143a32b801224128ae849c2e35c0a8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='fetching responses', max=500.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:26:53,620] WARNING:root: Missed Queries: 0\n",
      "[2020-07-11 19:26:53,644] INFO:root: Scores: {\n",
      "  \"perfect_rerank_score\": 1.1531107315227402,\n",
      "  \"perfect_rerank_error\": \"'None'\",\n",
      "  \"api_score\": 0.6130484828884987,\n",
      "  \"api_error\": \"'None'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claimant + Stopword Removal + Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expansion(claim):\n",
    "    claim_doc = nlp(claim.claim, disable=[\"textcat\", \"tagger\", \"parser\", \"ner\"])\n",
    "\n",
    "    # stopword removal\n",
    "    query_words = [token.text for token in claim_doc if not token.is_stop]\n",
    "    query = clean_text(\n",
    "        \" \".join(\n",
    "            [\n",
    "                t\n",
    "                for t in query_words\n",
    "                if t and not len(clean_text(t, remove_punctuation=True)) == 0\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if claim.claimant:\n",
    "        query += \" \" + claim.claimant\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6590c0bbf6db49e6aeb7fd0c3ab8831a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Phase2ValidationDataset to claims', max=500.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:26:53,963] INFO:valerie.datasets: missed row to claim conversions: 0\n",
      "[2020-07-11 19:26:53,964] INFO:valerie.datasets: Phase2ValidationDataset claims set change 500 --> 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b15205bd96d4d238c6d8d7cb6be40ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='fetching responses', max=500.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:29:06,225] WARNING:root: Missed Queries: 0\n",
      "[2020-07-11 19:29:06,245] INFO:root: Scores: {\n",
      "  \"perfect_rerank_score\": 1.168343222165067,\n",
      "  \"perfect_rerank_error\": \"'None'\",\n",
      "  \"api_score\": 0.6395182603952109,\n",
      "  \"api_error\": \"'None'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date + Stopword Removal + Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expansion(claim):\n",
    "    claim_doc = nlp(claim.claim, disable=[\"textcat\", \"tagger\", \"parser\", \"ner\"])\n",
    "\n",
    "    # stopword removal\n",
    "    query_words = [token.text for token in claim_doc if not token.is_stop]\n",
    "    query = clean_text(\n",
    "        \" \".join(\n",
    "            [\n",
    "                t\n",
    "                for t in query_words\n",
    "                if t and not len(clean_text(t, remove_punctuation=True)) == 0\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if claim.date:\n",
    "        query += \" \" + claim.date.split(\" \")[0].split(\"T\")[0]\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451ec6af35d7415b91e3f8e5065b67be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Phase2ValidationDataset to claims', max=500.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:29:06,438] INFO:valerie.datasets: missed row to claim conversions: 0\n",
      "[2020-07-11 19:29:06,439] INFO:valerie.datasets: Phase2ValidationDataset claims set change 500 --> 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a87b91aa3843dcb85538c224a06280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='fetching responses', max=500.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:31:13,856] WARNING:root: Missed Queries: 0\n",
      "[2020-07-11 19:31:13,885] INFO:root: Scores: {\n",
      "  \"perfect_rerank_score\": 1.1414155993456803,\n",
      "  \"perfect_rerank_error\": \"'None'\",\n",
      "  \"api_score\": 0.6440130304440003,\n",
      "  \"api_error\": \"'None'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claimant + Date + Stopword Removal + Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_expansion(claim):\n",
    "    claim_doc = nlp(claim.claim, disable=[\"textcat\", \"tagger\", \"parser\", \"ner\"])\n",
    "\n",
    "    # stopword removal\n",
    "    query_words = [token.text for token in claim_doc if not token.is_stop]\n",
    "    query = clean_text(\n",
    "        \" \".join(\n",
    "            [\n",
    "                t\n",
    "                for t in query_words\n",
    "                if t and not len(clean_text(t, remove_punctuation=True)) == 0\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if claim.date:\n",
    "        query += \" \" + claim.date.split(\" \")[0].split(\"T\")[0]\n",
    "\n",
    "    if claim.claimant:\n",
    "        query += \" \" + claim.claimant\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8877affc8d44ad888b5e1472382784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Phase2ValidationDataset to claims', max=500.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:31:14,105] INFO:valerie.datasets: missed row to claim conversions: 0\n",
      "[2020-07-11 19:31:14,106] INFO:valerie.datasets: Phase2ValidationDataset claims set change 500 --> 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c75b006d25248b7b92765d1f679291e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='fetching responses', max=500.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2020-07-11 19:33:25,713] WARNING:root: Missed Queries: 0\n",
      "[2020-07-11 19:33:25,746] INFO:root: Scores: {\n",
      "  \"perfect_rerank_score\": 1.1557801493610302,\n",
      "  \"perfect_rerank_error\": \"'None'\",\n",
      "  \"api_score\": 0.6617083840074162,\n",
      "  \"api_error\": \"'None'\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
